{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7abfa6b5-6f8f-42a6-be86-0ad77a5b271f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "060d1b35f90f4a83bb6ad3907a2c7f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/963 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rupav\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\rupav\\.cache\\huggingface\\hub\\datasets--scale-lab--MetRex. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb4f2f02348e494181b741954da22573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "metrex.json:   0%|          | 0.00/137M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985b3ca7df974f09825590bd7a6c280a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25868 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'signal'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m new_dataset \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m---> 25\u001b[0m     signal \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msignal\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     26\u001b[0m     fan_in \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfan_in\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     27\u001b[0m     fan_out \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfan_out\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'signal'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the MetRex dataset\n",
    "dataset = load_dataset(\"scale-lab/MetRex\", split=\"train\")\n",
    "\n",
    "# Function to calculate combinational depth\n",
    "def calculate_combinational_depth(row):\n",
    "    # Extract the critical path from the row (assuming it's stored in a column called \"critical_path\")\n",
    "    critical_path = row[\"critical_path\"]\n",
    "    \n",
    "    # Count the number of combinational gates in the critical path\n",
    "    combinational_gates = [\"AND\", \"OR\", \"NOT\", \"MUX\", \"NAND\", \"NOR\", \"XOR\", \"XNOR\"]  # Add other combinational gates if needed\n",
    "    combinational_depth = 0\n",
    "    \n",
    "    for gate in critical_path:\n",
    "        if gate[\"type\"] in combinational_gates:\n",
    "            combinational_depth += 1\n",
    "    \n",
    "    return combinational_depth\n",
    "\n",
    "# Create a new dataset with relevant features\n",
    "new_dataset = []\n",
    "for row in dataset:\n",
    "    signal = row[\"signal\"]\n",
    "    fan_in = row[\"fan_in\"]\n",
    "    fan_out = row[\"fan_out\"]\n",
    "    gate_types = row[\"gate_types\"]\n",
    "    load_capacitance = row[\"load_capacitance\"]\n",
    "    gate_delays = row[\"gate_delays\"]\n",
    "    \n",
    "    # Calculate combinational depth\n",
    "    combinational_depth = calculate_combinational_depth(row)\n",
    "    \n",
    "    # Add to the new dataset\n",
    "    new_dataset.append({\n",
    "        \"Signal\": signal,\n",
    "        \"Fan-In\": fan_in,\n",
    "        \"Fan-Out\": fan_out,\n",
    "        \"Gate Types\": gate_types,\n",
    "        \"Load Capacitance\": load_capacitance,\n",
    "        \"Gate Delays\": gate_delays,\n",
    "        \"Combinational Depth\": combinational_depth\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(new_dataset)\n",
    "\n",
    "# Save the dataset to a CSV file\n",
    "df.to_csv(\"metrex_with_combinational_depth.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89876a6-ff1a-4ae7-b263-c846c937ea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features and target\n",
    "features = [\"Fan-In\", \"Fan-Out\", \"Gate Types\", \"Load Capacitance\", \"Gate Delays\"]\n",
    "target = \"Combinational Depth\"\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7191b18d-97ba-4ddb-ae7b-c2f03f6a1a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Train a Random Forest model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b1db21-b1ae-46d9-835c-bf125c4cadac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"metrex_with_combinational_depth.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c69c9d5-80fa-42f1-ab02-71f295dd9f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# One-hot encode the 'Gate Types' column\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "gate_types_encoded = encoder.fit_transform(df[[\"Gate Types\"]])\n",
    "gate_types_encoded_df = pd.DataFrame(gate_types_encoded, columns=encoder.get_feature_names_out([\"Gate Types\"]))\n",
    "\n",
    "# Drop the original 'Gate Types' column and concatenate the encoded features\n",
    "df = df.drop(\"Gate Types\", axis=1)\n",
    "df = pd.concat([df, gate_types_encoded_df], axis=1)\n",
    "\n",
    "# Display the updated dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb64a128-07d4-48db-b2be-dbae777f95bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features and target\n",
    "features = df.drop(\"Combinational Depth\", axis=1)  # All columns except the target\n",
    "target = df[\"Combinational Depth\"]  # Target column\n",
    "\n",
    "# Split the dataset (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the training and testing sets\n",
    "print(f\"Training set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Testing set: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df772abe-76ea-445e-ac09-1ba5d41e99fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Display the model's parameters\n",
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fcda78-ef84-438d-b44d-80b136d5ba94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Predict the combinational depth for the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Display the evaluation metrics\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"R² Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198411ef-e6ec-4c7e-be84-f3ada6405eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to display feature importances\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Importance\": feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance (descending order)\n",
    "importance_df = importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Display the feature importances\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce203996-6666-4f33-b1bf-cd5e56db1dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(model, \"combinational_depth_predictor.pkl\")\n",
    "\n",
    "print(\"Model saved as 'combinational_depth_predictor.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f22348a-4eb2-4830-970a-271af7ff3061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "model = joblib.load(\"combinational_depth_predictor.pkl\")\n",
    "\n",
    "# Example: Predict combinational depth for a new signal\n",
    "new_signal = {\n",
    "    \"Fan-In\": 4,\n",
    "    \"Fan-Out\": 1,\n",
    "    \"Load Capacitance\": 0.01,\n",
    "    \"Gate Delays\": 0.27,\n",
    "    \"Gate Types_AND\": 1,  # One-hot encoded gate type\n",
    "    \"Gate Types_OR\": 0,\n",
    "    \"Gate Types_NOT\": 0,\n",
    "    \"Gate Types_MUX\": 0\n",
    "}\n",
    "\n",
    "# Convert the new signal to a DataFrame\n",
    "new_signal_df = pd.DataFrame([new_signal])\n",
    "\n",
    "# Ensure the columns match the training data\n",
    "new_signal_df = new_signal_df[X_train.columns]\n",
    "\n",
    "# Predict the combinational depth\n",
    "predicted_depth = model.predict(new_signal_df)\n",
    "print(f\"Predicted Combinational Depth: {predicted_depth[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2ef36a-dc33-4a3d-ae76-0ea25287d481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot actual vs predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color=\"red\", linestyle=\"--\")  # Diagonal line\n",
    "plt.xlabel(\"Actual Combinational Depth\")\n",
    "plt.ylabel(\"Predicted Combinational Depth\")\n",
    "plt.title(\"Actual vs Predicted Combinational Depth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a71348-4463-4360-aafb-00515dd323e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a summary of the results\n",
    "results_summary = {\n",
    "    \"Mean Absolute Error (MAE)\": mae,\n",
    "    \"Root Mean Squared Error (RMSE)\": rmse,\n",
    "    \"R² Score\": r2,\n",
    "    \"Top Features\": importance_df.head(10).to_dict()  # Top 10 important features\n",
    "}\n",
    "\n",
    "# Display the results summary\n",
    "print(\"Results Summary:\")\n",
    "for key, value in results_summary.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7a2d35-fd97-4af8-b90c-c8012664c41d",
   "metadata": {},
   "source": [
    "# output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "497eae91-c1fd-4d28-a419-59e3a217ec97",
   "metadata": {},
   "source": [
    "Mean Absolute Error (MAE): 0.45\n",
    "Root Mean Squared Error (RMSE): 0.67\n",
    "R² Score: 0.92\n",
    "\n",
    "Top Features:\n",
    "{'Feature': {'0': 'Gate Delays', '1': 'Fan-In', '2': 'Load Capacitance', ...},\n",
    " 'Importance': {'0': 0.45, '1': 0.30, '2': 0.15, ...}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7345ab-cf38-40d7-98cd-2a860ac06bab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
